{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日本語形態素解析器SudachiPyを使い複合名詞を取得する方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考リンク\n",
    "- https://github.com/WorksApplications/SudachiPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パッケージとトークナイザーの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのインポート\n",
    "\n",
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudachipyのtokenizerとmodeのセット\n",
    "\n",
    "tokenizer_obj = dictionary.Dictionary().create()\n",
    "mode = tokenizer.Tokenizer.SplitMode.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['国家公務員']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 出力のテスト\n",
    "\n",
    "[m.surface() for m in tokenizer_obj.tokenize(\"国家公務員\", mode)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト文とその形態素結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "応用例は自然言語処理（機械翻訳・かな漢字変換・構文解析等）、専門家の推論・判断を模倣するエキスパートシステム、画像データを解析して特定のパターンを検出・抽出したりする画像認識等がある\n"
     ]
    }
   ],
   "source": [
    "sent1 = '応用例は自然言語処理（機械翻訳・かな漢字変換・構文解析等）、専門家の推論・判断を模倣するエキスパートシステム、画像データを解析して特定のパターンを検出・抽出したりする画像認識等がある'\n",
    "print(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "応用 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "例 ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "は ['助詞', '係助詞', '*', '*', '*', '*']\n",
      "自然言語処理 ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "（ ['補助記号', '括弧開', '*', '*', '*', '*']\n",
      "機械 ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "翻訳 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "・ ['補助記号', '一般', '*', '*', '*', '*']\n",
      "かな ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "漢字 ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "変換 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "・ ['補助記号', '一般', '*', '*', '*', '*']\n",
      "構文 ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "解析 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "等 ['接尾辞', '名詞的', '一般', '*', '*', '*']\n",
      "） ['補助記号', '括弧閉', '*', '*', '*', '*']\n",
      "、 ['補助記号', '読点', '*', '*', '*', '*']\n",
      "専門家 ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "の ['助詞', '格助詞', '*', '*', '*', '*']\n",
      "推論 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "・ ['補助記号', '一般', '*', '*', '*', '*']\n",
      "判断 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "を ['助詞', '格助詞', '*', '*', '*', '*']\n",
      "模倣 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "する ['動詞', '非自立可能', '*', '*', 'サ行変格', '連体形-一般']\n",
      "エキスパートシステム ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "、 ['補助記号', '読点', '*', '*', '*', '*']\n",
      "画像データ ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "を ['助詞', '格助詞', '*', '*', '*', '*']\n",
      "解析 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "し ['動詞', '非自立可能', '*', '*', 'サ行変格', '連用形-一般']\n",
      "て ['助詞', '接続助詞', '*', '*', '*', '*']\n",
      "特定 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "の ['助詞', '格助詞', '*', '*', '*', '*']\n",
      "パターン ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "を ['助詞', '格助詞', '*', '*', '*', '*']\n",
      "検出 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "・ ['補助記号', '一般', '*', '*', '*', '*']\n",
      "抽出 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "し ['動詞', '非自立可能', '*', '*', 'サ行変格', '連用形-一般']\n",
      "たり ['助詞', '副助詞', '*', '*', '*', '*']\n",
      "する ['動詞', '非自立可能', '*', '*', 'サ行変格', '連体形-一般']\n",
      "画像 ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "認識 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "等 ['接尾辞', '名詞的', '一般', '*', '*', '*']\n",
      "が ['助詞', '格助詞', '*', '*', '*', '*']\n",
      "ある ['動詞', '非自立可能', '*', '*', '五段-ラ行', '終止形-一般']\n"
     ]
    }
   ],
   "source": [
    "for token in tokenizer_obj.tokenize(sent1, mode):\n",
    "    print(token.surface(), token.part_of_speech())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990年、3D印刷ともっとも広く関連づけられるPlastics extrusion技術が、Stratasys社により\"fused deposition modeling (FDM)\"（熱溶解積層法）として商品化された\n"
     ]
    }
   ],
   "source": [
    "sent2 = '1990年、3D印刷ともっとも広く関連づけられるPlastics extrusion技術が、Stratasys社により\"fused deposition modeling (FDM)\"（熱溶解積層法）として商品化された'\n",
    "print(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990 ['名詞', '数詞', '*', '*', '*', '*']\n",
      "年 ['名詞', '普通名詞', '助数詞可能', '*', '*', '*']\n",
      "、 ['補助記号', '読点', '*', '*', '*', '*']\n",
      "3 ['名詞', '数詞', '*', '*', '*', '*']\n",
      "D ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "印刷 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "と ['助詞', '格助詞', '*', '*', '*', '*']\n",
      "もっとも ['副詞', '*', '*', '*', '*', '*']\n",
      "広く ['形容詞', '一般', '*', '*', '形容詞', '連用形-一般']\n",
      "関連 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "づけ ['動詞', '非自立可能', '*', '*', '下一段-カ行', '未然形-一般']\n",
      "られる ['助動詞', '*', '*', '*', '助動詞-レル', '連体形-一般']\n",
      "Plastics ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "  ['空白', '*', '*', '*', '*', '*']\n",
      "extrusion ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "技術 ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "が ['助詞', '格助詞', '*', '*', '*', '*']\n",
      "、 ['補助記号', '読点', '*', '*', '*', '*']\n",
      "Stratasys ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "社 ['名詞', '普通名詞', '助数詞可能', '*', '*', '*']\n",
      "に ['助詞', '格助詞', '*', '*', '*', '*']\n",
      "より ['動詞', '一般', '*', '*', '五段-ラ行', '連用形-一般']\n",
      "\" ['補助記号', '一般', '*', '*', '*', '*']\n",
      "fused ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "  ['空白', '*', '*', '*', '*', '*']\n",
      "deposition ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "  ['空白', '*', '*', '*', '*', '*']\n",
      "modeling ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "  ['空白', '*', '*', '*', '*', '*']\n",
      "( ['補助記号', '括弧開', '*', '*', '*', '*']\n",
      "FDM ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      ") ['補助記号', '括弧閉', '*', '*', '*', '*']\n",
      "\" ['補助記号', '一般', '*', '*', '*', '*']\n",
      "（ ['補助記号', '括弧開', '*', '*', '*', '*']\n",
      "熱 ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "溶解 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "積層 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "法 ['名詞', '普通名詞', '一般', '*', '*', '*']\n",
      "） ['補助記号', '括弧閉', '*', '*', '*', '*']\n",
      "と ['助詞', '格助詞', '*', '*', '*', '*']\n",
      "し ['動詞', '非自立可能', '*', '*', 'サ行変格', '連用形-一般']\n",
      "て ['助詞', '接続助詞', '*', '*', '*', '*']\n",
      "商品化 ['名詞', '普通名詞', 'サ変可能', '*', '*', '*']\n",
      "さ ['動詞', '非自立可能', '*', '*', 'サ行変格', '未然形-サ']\n",
      "れ ['助動詞', '*', '*', '*', '助動詞-レル', '連用形-一般']\n",
      "た ['助動詞', '*', '*', '*', '助動詞-タ', '終止形-一般']\n"
     ]
    }
   ],
   "source": [
    "for token in tokenizer_obj.tokenize(sent2, mode):\n",
    "    print(token.surface(), token.part_of_speech())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 複合名詞（接頭辞や接尾辞あるなしなどの調整可能）を含む形での分かち書き"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークナイザーのラッパーとなる自作関数\n",
    "\n",
    "def custom_tokenize(sentence):\n",
    "    tokens = []\n",
    "    nouns = []\n",
    "    \n",
    "    is_continuous = False   \n",
    "    for i, token in enumerate(sentence):\n",
    "        word = token.surface()\n",
    "\n",
    "        # 複合名詞として連結する品詞の選択\n",
    "        tag_split = token.part_of_speech()\n",
    "        if tag_split[0] == '接頭辞':\n",
    "            is_use = True\n",
    "        elif tag_split[0] == '名詞' and tag_split[1] != '接尾語' and tag_split[2] != '副詞可能':\n",
    "            is_use = True\n",
    "        elif tag_split[0] == '接尾辞' and tag_split[1] == '名詞的':\n",
    "            is_use = True\n",
    "        else:\n",
    "            is_use = False       \n",
    "\n",
    "        # gather adjacent nouns and concat them\n",
    "        if i == len(sentence) - 1:\n",
    "            if is_use and is_continuous:\n",
    "                term_current.append(word)\n",
    "                tokens.append(\"\".join(term_current))\n",
    "                nouns.append(\"\".join(term_current))\n",
    "            else:\n",
    "                tokens.append(word)        \n",
    "        else:      \n",
    "            if is_use:            \n",
    "                if is_continuous == False:\n",
    "                    is_continuous = True\n",
    "                    term_current = [word]\n",
    "                else:\n",
    "                    term_current.append(word)\n",
    "            else:\n",
    "                if is_continuous == True:\n",
    "                    is_continuous = False\n",
    "                    tokens.append(\"\".join(term_current))\n",
    "                    nouns.append(\"\".join(term_current))\n",
    "                tokens.append(word)\n",
    "            \n",
    "    return tokens, nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト文への実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['応用例', 'は', '自然言語処理', '（', '機械翻訳', '・', 'かな漢字変換', '・', '構文解析等', '）', '、', '専門家', 'の', '推論', '・', '判断', 'を', '模倣', 'する', 'エキスパートシステム', '、', '画像データ', 'を', '解析', 'し', 'て', '特定', 'の', 'パターン', 'を', '検出', '・', '抽出', 'し', 'たり', 'する', '画像認識等', 'が', 'ある']\n",
      "['応用例', '自然言語処理', '機械翻訳', 'かな漢字変換', '構文解析等', '専門家', '推論', '判断', '模倣', 'エキスパートシステム', '画像データ', '解析', '特定', 'パターン', '検出', '抽出', '画像認識等']\n"
     ]
    }
   ],
   "source": [
    "tokens, noun = custom_tokenize(tokenizer_obj.tokenize(sent1, mode))\n",
    "\n",
    "print(tokens)\n",
    "print(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1990年', '、', '3D印刷', 'と', 'もっとも', '広く', '関連', 'づけ', 'られる', 'Plastics', ' ', 'extrusion技術', 'が', '、', 'Stratasys社', 'に', 'より', '\"', 'fused', ' ', 'deposition', ' ', 'modeling', ' ', '(', 'FDM', ')', '\"', '（', '熱溶解積層法', '）', 'と', 'し', 'て', '商品化', 'さ', 'れ', 'た']\n",
      "['1990年', '3D印刷', '関連', 'Plastics', 'extrusion技術', 'Stratasys社', 'fused', 'deposition', 'modeling', 'FDM', '熱溶解積層法', '商品化']\n"
     ]
    }
   ],
   "source": [
    "tokens, noun = custom_tokenize(tokenizer_obj.tokenize(sent2, mode))\n",
    "\n",
    "print(tokens)\n",
    "print(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接尾辞がいらないときなどは、連結する品詞選択の箇所を調整する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenize(sentence):\n",
    "    tokens = []\n",
    "    nouns = []\n",
    "    \n",
    "    is_continuous = False   \n",
    "    for i, token in enumerate(sentence):\n",
    "        word = token.surface()\n",
    "\n",
    "        # 複合名詞として連結する品詞の選択\n",
    "        tag_split = token.part_of_speech()\n",
    "        if tag_split[0] == '接頭辞':\n",
    "            is_use = True\n",
    "        elif tag_split[0] == '名詞' and tag_split[1] != '接尾語' and tag_split[2] != '副詞可能':\n",
    "            is_use = True\n",
    "#         elif tag_split[0] == '接尾辞' and tag_split[1] == '名詞的':\n",
    "#             is_use = True\n",
    "        else:\n",
    "            is_use = False       \n",
    "\n",
    "        # gather adjacent nouns and concat them\n",
    "        if i == len(sentence) - 1:\n",
    "            if is_use and is_continuous:\n",
    "                term_current.append(word)\n",
    "                tokens.append(\"\".join(term_current))\n",
    "                nouns.append(\"\".join(term_current))\n",
    "            else:\n",
    "                tokens.append(word)        \n",
    "        else:      \n",
    "            if is_use:            \n",
    "                if is_continuous == False:\n",
    "                    is_continuous = True\n",
    "                    term_current = [word]\n",
    "                else:\n",
    "                    term_current.append(word)\n",
    "            else:\n",
    "                if is_continuous == True:\n",
    "                    is_continuous = False\n",
    "                    tokens.append(\"\".join(term_current))\n",
    "                    nouns.append(\"\".join(term_current))\n",
    "                tokens.append(word)\n",
    "            \n",
    "    return tokens, nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['応用例', 'は', '自然言語処理', '（', '機械翻訳', '・', 'かな漢字変換', '・', '構文解析', '等', '）', '、', '専門家', 'の', '推論', '・', '判断', 'を', '模倣', 'する', 'エキスパートシステム', '、', '画像データ', 'を', '解析', 'し', 'て', '特定', 'の', 'パターン', 'を', '検出', '・', '抽出', 'し', 'たり', 'する', '画像認識', '等', 'が', 'ある']\n",
      "['応用例', '自然言語処理', '機械翻訳', 'かな漢字変換', '構文解析', '専門家', '推論', '判断', '模倣', 'エキスパートシステム', '画像データ', '解析', '特定', 'パターン', '検出', '抽出', '画像認識']\n"
     ]
    }
   ],
   "source": [
    "tokens, noun = custom_tokenize(tokenizer_obj.tokenize(sent1, mode))\n",
    "\n",
    "print(tokens)\n",
    "print(noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 複合名詞とそれを構成する個別名詞の同時出力\n",
    "ABCという複合名詞があった場合に、A,B,C,AB,ABCを出力する。極めてレアな複合名詞などを扱うときに情報量を増やすときなどの用途用  \n",
    "例）熱溶解積層法 => '熱', '溶解', '積層', '法', '熱溶解', '熱溶解積層', '熱溶解積層法'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compound_noun(sentence, has_origins=True):\n",
    "    nouns = []\n",
    "    \n",
    "    is_continuous = False   \n",
    "    for i, token in enumerate(sentence):\n",
    "        word = token.surface()\n",
    "\n",
    "        # 複合名詞として連結する品詞の選択\n",
    "        tag_split = token.part_of_speech()\n",
    "        if tag_split[0] == '名詞' and tag_split[1] != '接尾語' and tag_split[2] != '副詞可能':\n",
    "            is_use = True\n",
    "        else:\n",
    "            is_use = False       \n",
    "\n",
    "        # gather adjacent nouns and concat them\n",
    "        if i == len(sentence) - 1:\n",
    "            if is_use and is_continuous:\n",
    "                term_current.append(word)\n",
    "                if has_origins:\n",
    "                    compound = term_current + [\"\".join(term_current[:i+1]) for i in range(1, len(term_current))]\n",
    "                    nouns.append(compound)\n",
    "                else:\n",
    "                    nouns.append(\"\".join(term_current))\n",
    "                \n",
    "        else:      \n",
    "            if is_use:            \n",
    "                if is_continuous == False:\n",
    "                    is_continuous = True\n",
    "                    term_current = [word]\n",
    "                else:\n",
    "                    term_current.append(word)\n",
    "            else:\n",
    "                if is_continuous == True:\n",
    "                    is_continuous = False\n",
    "                    if has_origins:\n",
    "                        compound = term_current + [\"\".join(term_current[:i+1]) for i in range(1, len(term_current))]\n",
    "                        nouns.append(compound)\n",
    "                    else:\n",
    "                        nouns.append(\"\".join(term_current))                    \n",
    "            \n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト文への実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['応用', '例', '応用例'], ['自然言語処理'], ['機械', '翻訳', '機械翻訳'], ['かな', '漢字', '変換', 'かな漢字', 'かな漢字変換'], ['構文', '解析', '構文解析'], ['専門家'], ['推論'], ['判断'], ['模倣'], ['エキスパートシステム'], ['画像データ'], ['解析'], ['特定'], ['パターン'], ['検出'], ['抽出'], ['画像', '認識', '画像認識']]\n"
     ]
    }
   ],
   "source": [
    "compounds = get_compound_noun(tokenizer_obj.tokenize(sent1, mode))\n",
    "\n",
    "print(compounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1990', '年', '1990年'], ['3', 'D', '印刷', '3D', '3D印刷'], ['関連'], ['Plastics'], ['extrusion', '技術', 'extrusion技術'], ['Stratasys', '社', 'Stratasys社'], ['fused'], ['deposition'], ['modeling'], ['FDM'], ['熱', '溶解', '積層', '法', '熱溶解', '熱溶解積層', '熱溶解積層法'], ['商品化']]\n"
     ]
    }
   ],
   "source": [
    "compounds = get_compound_noun(tokenizer_obj.tokenize(sent2, mode))\n",
    "\n",
    "print(compounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# あとは、出力された名詞をさらに、後処理をしてノイズを除去するなどする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy ginzaで名詞句を撮ってきた場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('ja_ginza_electra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "応用例\n",
      "自然言語処理\n",
      "特定\n",
      "パターンを検出・抽出したりする画像認識等\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(sent1)\n",
    "\n",
    "for span in doc.noun_chunks:\n",
    "    print(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990年\n",
      "3D印刷\n",
      "もっとも広く関連づけられるPlastics extrusion技術\n",
      "Stratasys社\n",
      "\"fused deposition modeling\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(sent2)\n",
    "\n",
    "for span in doc.noun_chunks:\n",
    "    print(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv3.7",
   "language": "python",
   "name": "pyenv3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
